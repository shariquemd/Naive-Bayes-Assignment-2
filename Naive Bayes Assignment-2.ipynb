{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b96c3b31-00fd-4852-aa13-c0779fd263a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "Answer1.To calculate the probability that an employee is a smoker given that he/she uses the health insurance plan, you can use Bayes' theorem. Let:\n",
    "\n",
    "p(A|B)=(P(A).P(B|A))/P(B)\n",
    "        =(0.4*1)/0.7\n",
    "        =0.57\n",
    "\n",
    "\n",
    "Answer2. The main difference between Bernoulli Naive Bayes and Multinomial Naive Bayes lies in the type of data they are suitable for. Bernoulli Naive Bayes is designed for binary and boolean features, while Multinomial Naive Bayes is used for discrete data, often for document classification where features represent word counts.\n",
    "\n",
    "Answer3. Bernoulli Naive Bayes assumes that features are binary, so it can handle missing values by considering them as the absence of the feature, assuming the feature is binary. However, it's essential to preprocess the data appropriately to represent missing values as the absence of a feature.\n",
    "\n",
    "Answer4. Yes, Gaussian Naive Bayes can be used for multi-class classification. It extends naturally to handle multiple classes by estimating the mean and variance for each class.\n",
    "\n",
    "Answer5:\n",
    "import pandas as pd\n",
    "import requests\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict, KFold\n",
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB, GaussianNB\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Download the Spambase dataset using requests\n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/spambase/spambase.data\"\n",
    "response = requests.get(url)\n",
    "df = pd.read_csv(pd.compat.StringIO(response.text), header=None)\n",
    "\n",
    "# Assuming the last column is the target variable and the rest are features\n",
    "X = df.iloc[:, :-1]\n",
    "y = df.iloc[:, -1]\n",
    "\n",
    "# Implement Bernoulli Naive Bayes\n",
    "bnb = BernoulliNB()\n",
    "bnb_scores = cross_val_score(bnb, X, y, cv=KFold(n_splits=10, shuffle=True, random_state=42), scoring='accuracy')\n",
    "\n",
    "# Implement Multinomial Naive Bayes\n",
    "mnb = MultinomialNB()\n",
    "mnb_scores = cross_val_score(mnb, X, y, cv=KFold(n_splits=10, shuffle=True, random_state=42), scoring='accuracy')\n",
    "\n",
    "# Implement Gaussian Naive Bayes\n",
    "gnb = GaussianNB()\n",
    "gnb_scores = cross_val_score(gnb, X, y, cv=KFold(n_splits=10, shuffle=True, random_state=42), scoring='accuracy')\n",
    "\n",
    "# Report performance metrics\n",
    "def print_metrics(name, scores):\n",
    "    print(f\"{name} Classifier:\")\n",
    "    print(\"Accuracy:\", scores.mean())\n",
    "    print(\"Precision:\", precision_score(y, cross_val_predict(bnb, X, y, cv=KFold(n_splits=10, shuffle=True, random_state=42)), average='macro'))\n",
    "    print(\"Recall:\", recall_score(y, cross_val_predict(bnb, X, y, cv=KFold(n_splits=10, shuffle=True, random_state=42)), average='macro'))\n",
    "    print(\"F1 Score:\", f1_score(y, cross_val_predict(bnb, X, y, cv=KFold(n_splits=10, shuffle=True, random_state=42)), average='macro'))\n",
    "    print(\"\\n\")\n",
    "\n",
    "print_metrics(\"Bernoulli\", bnb_scores)\n",
    "print_metrics(\"Multinomial\", mnb_scores)\n",
    "print_metrics(\"Gaussian\", gnb_scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a8b657d-c9b6-4415-a1a7-fdb04eb75e98",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
